1) Si è deciso di modificare il file Geography(fast).py e in particolare l’ algoritmo che  mappa ciascuna coppia di coordinate <latitudine,longitudine> con la relativa città e il relativo stato.(nella versione precedente il calcolo delle distanze oltre a essere computazionalmente elevato,era anche fin troppo approssimato).
La logica del nuovo algoritmo è pressoché simile a quella adoperata precedentemente:calcolo distanza coppia <lat,long> nei due dataset Police.csv e uscities.csv,  e se questa è  inferiore o uguale a una certa threshold, si procede con il mapping corrispondente della relativa città e stato. Dopo aver trovato tutte le coppie nel raggio di una certa thresold, tale soglia viene incrementata affinché si possano esplorare nuove tuple aventi una distanza maggiore(rispetto alla precedente) ma che trovino un mapping opportuno. Tale logica viene ripetuta finché tutte le coordinate geografiche relative alle custodie del file Police.csv non sono state mappate con un opportuna città e stato.
Per rendere  l'algoritmo più efficiente dal punto di vista computazionale, è stata utilizzata una struttura dati KDTree che permette di organizzare  i punti in uno spazio a dimensione K e di trovare rapidamente i punti più vicini in uno spazio multidimensionale.
Come metrica per la distanza, in questa nuova versione, è stata utilizzata la distanza Euclidea(a differenza della distanza di Manatthan usata nella versione precedente).

2) Si è deciso di aggiungere lo script truncate.py che, se eseguito, permette di cancellare tutti i dati contenuti attualmente nelle tabelle che definiscono lo schema di dati su SQL Server. Lo script potrebbe essere utile per spopolare le tabelle in caso di errori nella scrittura dei dati relativi a un precedente tentativo di caricamento tramite l'apposito script.

